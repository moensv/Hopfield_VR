\section{Exercise 4: Dale's law}

\begin{itshape}
\small
Set $c=0.1$, $N = 200$ and turn off random asymmetry ($p_{cut} = 0$). Set $E \in \l[0, 1\r]$ to be the percentage of excitatory nodes.

For a given $E$, randomly split the network into an excitatory and an inhibitory subpopulation (of sizes $E \cdot N$ and $(1 - E) \cdot N$ respectively). Now enforce Dale's law on the network connectivity by setting "disallowed" connection weights in the standard Hebbian weight matrix Eq. 1 to zero.

What percentage of the directed connections do you expect to be cut for $E = \frac{1}{2}$
As in Ex. 2 calculate and plot the mean $\alpha_{N,max}$ for varying E with error bars (at least 10 repetitions). Interpret the results and compare the value for E$ = 1$ to your result from Ex. 3.
\end{itshape}

\paragraph*{}

As a reminder Dale's law is restated; \textit{for each neuron, synaptic connections to postsynaptic neurons are either of the excitatory or inhibitory type, never both} (Exercise Sheet).

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.6\textwidth]{dat/ex4-mean_max_load-N200-Q50-C95.png}
  \end{center}
  \vspace{-20pt}
  \caption{Exercise 4: Mean maximal load over different E}
  \label{fig: exercise 4}
\end{figure}

\paragraph*{}
When E increases from 0 to 0.7, the mean maximal load decreases. After 0.7 it flattens out and then starts increasing again just before E $= 1$. E $=1$ means that all nodes are excitatory and therefore all weights positive as can be deduced from equation \ref{eq: weights}. As shown in figure \ref{fig: exercise 4}, the mean maximal load is expected to decrease as E increases. 

\paragraph*{}
Because all patterns $\xi_i$ are completely random and the weight matrix symmetric we expect that half the nodes are cut for all E, and thus also for $E = \frac{1}{2}$.
So the maximal available load should be $\alpha_{N,max} = 0.08$ as can be read from table \ref{tbl:exercise3_CI}. 

\paragraph*{}
In figure \ref{fig: exercise 4} we find a maximal values of $\alpha_{N,max} = 0.11 $ for $E=0$. We thus improve our network and find better results by enforcing Dale's law for the region $E \in [0 \ldots 0.4]$, compared to $p_{cut} =0.5$. For a higher share in excitatory nodes in the network, enforcing Dale's law becomes less efficient than cutting the weights using the method from exercise 3. For E $ = 1$ the $\alpha_{N,max}=0.065$ is slightly lower than the random cut  value of 0.075, which can be deduced from figure \ref{fig:exercise3} where the value is $0.585*0.1278=0.0748$.

\paragraph*{}
This shows that a high excitatory share in the nodes is worse than a random cut of the same size. For low excitatory shares, enforcing Dale's law is more effective than using randomly cut values. A Hopfield neuron model that includes Dale's law is thus not just more realistic but also more effective in recovering patterns. 


	